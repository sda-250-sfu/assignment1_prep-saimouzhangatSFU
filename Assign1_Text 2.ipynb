{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text 2: Perspective articles (published in domain-specific academic journal)\n",
    "New England Joural of Medicine Retrieved from https://www.nejm.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment the text into words\n",
    "NEJM_words = texts.words('new_england_journal_of_medicine_perspectives.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'Half', '-', 'Century', 'of', 'Progress', 'in', ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEJM_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4991"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of words for NEJM.txt\n",
    "len(NEJM_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to calculate the lexical diversity\n",
    "def lexical_diversity(nameOfSource):\n",
    "    lexdiv= len(nameOfSource)/len(set(nameOfSource))\n",
    "    return lexdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3317757009345796"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the lexcial diversity of NEJM.txt\n",
    "lexical_diversity(NEJM_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'Half', '-', 'Century', 'of', 'Progress', 'in', 'Health', ':', 'The', 'National', 'Academy', 'of', 'Medicine', 'at', '50'], ['Vaccine', 'Innovations', '—', 'Past', 'and', 'Future'], ...]\n"
     ]
    }
   ],
   "source": [
    "# Segment sentences from the three texts\n",
    "NEJM_sentences = texts.sents('new_england_journal_of_medicine_perspectives.txt')\n",
    "print(NEJM_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "# Count the length of longest sentence in NEJM.txt\n",
    "NEJM__longest_sentence_length = max(len(s) for s in NEJM_sentences)\n",
    "print(NEJM__longest_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Other', 'information', 'gaps', 'will', 'include', 'more', 'comprehensive', 'assessments', 'of', 'short', '-', 'term', 'safety', ',', 'knowledge', 'of', 'whether', 'waning', 'of', 'vaccineinduced', 'protection', 'may', 'lead', 'to', 'vaccine', '-', 'enhanced', 'disease', 'if', 'a', 'vaccinee', 'becomes', 'infected', 'on', 'exposure', 'to', 'SARS', '-', 'CoV', '-', '2', ',', 'information', 'on', 'protection', 'against', 'clinically', 'severe', 'forms', 'of', 'Covid', '-', '19', ',', 'and', 'knowledge', 'of', 'any', 'associations', 'between', 'the', 'degree', 'of', 'protection', 'and', 'the', 'recipient', '’', 's', 'age', 'or', 'coexisting', 'conditions', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Find the longest sentence in NEJM.txt\n",
    "NEJM_longest_sentence = [s for s in NEJM_sentences if len(s) == NEJM__longest_sentence_length]\n",
    "print(NEJM_longest_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other\n",
      "inform\n",
      "gap\n",
      "will\n",
      "includ\n",
      "more\n",
      "comprehens\n",
      "assess\n",
      "of\n",
      "short-term\n",
      "safeti\n",
      ",\n",
      "knowledg\n",
      "of\n",
      "whether\n",
      "wane\n",
      "of\n",
      "vaccineinduc\n",
      "protect\n",
      "may\n",
      "lead\n",
      "to\n",
      "vaccine-enhanc\n",
      "diseas\n",
      "if\n",
      "a\n",
      "vaccine\n",
      "becom\n",
      "infect\n",
      "on\n",
      "exposur\n",
      "to\n",
      "sars-cov-2\n",
      ",\n",
      "inform\n",
      "on\n",
      "protect\n",
      "against\n",
      "clinic\n",
      "sever\n",
      "form\n",
      "of\n",
      "covid-19\n",
      ",\n",
      "and\n",
      "knowledg\n",
      "of\n",
      "ani\n",
      "associ\n",
      "between\n",
      "the\n",
      "degre\n",
      "of\n",
      "protect\n",
      "and\n",
      "the\n",
      "recipi\n",
      "’\n",
      "s\n",
      "age\n",
      "or\n",
      "coexist\n",
      "condit\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Stem the longest sentence for NEJM.txt\n",
    "NEJM_longest_sentence_text = \"Other information gaps will include more comprehensive assessments of short-term safety, knowledge of whether waning of vaccineinduced protection may lead to vaccine-enhanced disease if a vaccinee becomes infected on exposure to SARS-CoV-2, information on protection against clinically severe forms of Covid-19, and knowledge of any associations between the degree of protection and the recipient’s age or coexisting conditions.\"\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "porter = PorterStemmer()\n",
    "NEJM_longest_sentence_tokenized = word_tokenize(NEJM_longest_sentence_text)\n",
    "for t in NEJM_longest_sentence_tokenized:\n",
    "    print(porter.stem(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public health; United States; clinical laboratories; placebo\n",
      "recipients; adverse events; infectious diseases; regulatory processes;\n",
      "blinded follow-up; National Academy; Placebo-Controlled Trials;\n",
      "navigate regulations; emergency use; Health Organization; World\n",
      "Health; Disease Control; decision making; placebo-controlled trials;\n",
      "immune system; safety concerns; surveillance testing\n"
     ]
    }
   ],
   "source": [
    "# find the top collocations \n",
    "import nltk\n",
    "filePath2 = \"./data/new_england_journal_of_medicine_perspectives.txt\"\n",
    "\n",
    "\n",
    "# open the file as \"r\" or read only and store this opened file in f\n",
    "with open(filePath2, \"r\") as f:\n",
    "    # read the data from f and store it in the string variable \"data\"\n",
    "    NEJM_data = f.read()\n",
    "    \n",
    "NEJM_tokens = nltk.word_tokenize(NEJM_data)\n",
    "NEJM_text = nltk.Text(NEJM_tokens)\n",
    "NEJM_text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "a\n",
      "are\n",
      "as\n",
      "an\n",
      "at\n",
      "about\n",
      "access\n",
      "available\n",
      "after\n",
      "against\n",
      "all\n",
      "any\n",
      "also\n",
      "among\n",
      "according\n",
      "associated\n",
      "address\n",
      "adverse\n",
      "appropriate\n",
      "addition\n",
      "approval\n",
      "administered\n",
      "approved\n",
      "administration\n",
      "additional\n",
      "asymptomatic\n",
      "allocation\n",
      "affordable\n",
      "authorized\n",
      "age\n",
      "assessments\n",
      "administer\n",
      "areas\n",
      "aren\n",
      "antibody\n",
      "attenuated\n",
      "assignments\n",
      "answers\n",
      "assigned\n",
      "already\n",
      "acceptance\n",
      "alone\n",
      "ages\n",
      "achieving\n",
      "ago\n",
      "authoritative\n",
      "achievement\n",
      "attributable\n",
      "accomplishment\n",
      "announced\n",
      "achievements\n",
      "adults\n",
      "advances\n",
      "alarms\n",
      "assess\n",
      "autism\n",
      "accessible\n",
      "always\n",
      "availability\n",
      "amplify\n",
      "agents\n",
      "appear\n",
      "airborne\n",
      "animals\n",
      "able\n",
      "antibodies\n",
      "aims\n",
      "academic\n",
      "audio\n",
      "announcements\n",
      "appears\n",
      "associations\n",
      "ad\n",
      "assign\n",
      "altruistic\n",
      "amenable\n",
      "attack\n",
      "analyzed\n",
      "attributed\n",
      "anecdotes\n",
      "appropriately\n",
      "assessment\n",
      "accompanied\n",
      "allocating\n",
      "attempts\n",
      "ascertain\n",
      "accelerate\n",
      "adequate\n",
      "assessing\n",
      "authorities\n",
      "achieve\n",
      "average\n",
      "asking\n",
      "answer\n",
      "authorizations\n",
      "allow\n",
      "added\n",
      "absence\n",
      "acid\n",
      "adaptable\n",
      "adequately\n",
      "allotted\n",
      "at-risk\n",
      "authorization\n",
      "altogether\n",
      "agency\n",
      "applicants\n",
      "allowing\n",
      "acquire\n",
      "authority\n",
      "amplification\n",
      "alternatives\n",
      "arrives\n"
     ]
    }
   ],
   "source": [
    "# find top words starting with \"a\". The ten top words include and, a, are, as, an, at, about, access, available, after\n",
    "from nltk import FreqDist\n",
    "NEJM_fdist = FreqDist(NEJM_text)\n",
    "for w in NEJM_fdist:\n",
    "    if w.startswith('a'):\n",
    "        print(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effective\n",
      "efficacy\n",
      "evidence\n",
      "early\n",
      "events\n",
      "even\n",
      "estimated\n",
      "emergency\n",
      "ethically\n",
      "existing\n",
      "encourage\n",
      "ensure\n",
      "effects\n",
      "emerge\n",
      "efforts\n",
      "example\n",
      "either\n",
      "enough\n",
      "enable\n",
      "eradication\n",
      "effort\n",
      "enhanced\n",
      "ethical\n",
      "essential\n",
      "evaluation\n",
      "exposure\n",
      "evaluate\n",
      "eventually\n",
      "efficiency\n",
      "equipment\n",
      "enhance\n",
      "evidence-based\n",
      "exceeded\n",
      "eliminated\n",
      "executive\n",
      "eradicated\n",
      "eligible\n",
      "evaluated\n",
      "evolved\n",
      "ecosystem\n",
      "exist\n",
      "epidemics\n",
      "epidemic\n",
      "experimental\n",
      "envelope\n",
      "establishing\n",
      "emerging\n",
      "everyone\n",
      "emerged\n",
      "enroll\n",
      "elucidate\n",
      "enhancing\n",
      "each\n",
      "ensuring\n",
      "explained\n",
      "exaggerating\n",
      "especially\n",
      "elsewhere\n",
      "efficient\n",
      "evaluating\n",
      "earning\n",
      "end\n",
      "enter\n",
      "exceeds\n",
      "establish\n",
      "easily\n",
      "expansion\n",
      "expenses\n",
      "e.g.\n",
      "expertise\n",
      "ease\n",
      "emergent\n",
      "empower\n",
      "expectations\n",
      "established\n",
      "engineered\n",
      "entity\n",
      "equitable\n",
      "economic\n",
      "easy-to-use\n",
      "explored\n",
      "enables\n",
      "emergence\n"
     ]
    }
   ],
   "source": [
    "# find top words starting with \"e\". The ten top words include effective, efficacy, evidence, early, events, even, estimated, emergency, ethically, existing, encourage\n",
    "for w in NEJM_fdist:\n",
    "    if w.startswith('e'):\n",
    "        print(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "is\n",
      "important\n",
      "if\n",
      "it\n",
      "including\n",
      "investigational\n",
      "information\n",
      "its\n",
      "include\n",
      "infectious\n",
      "improve\n",
      "incentives\n",
      "innovative\n",
      "immunization\n",
      "infection\n",
      "influenza\n",
      "into\n",
      "incidence\n",
      "included\n",
      "increase\n",
      "isn\n",
      "immune\n",
      "interactions\n",
      "infected\n",
      "identified\n",
      "identify\n",
      "identifying\n",
      "institute\n",
      "illustrates\n",
      "inception\n",
      "issues\n",
      "illnesses\n",
      "immunization-related\n",
      "invasive\n",
      "inf\n",
      "issued\n",
      "improvements\n",
      "international\n",
      "imperative\n",
      "itself\n",
      "independent\n",
      "increasingly\n",
      "infections\n",
      "identification\n",
      "institutions\n",
      "inactivated\n",
      "interview\n",
      "improving\n",
      "insights\n",
      "initial\n",
      "increasing\n",
      "inform\n",
      "interpretation\n",
      "incorrectly\n",
      "immediate\n",
      "intervention\n",
      "instead\n",
      "informed\n",
      "impact\n",
      "inevitably\n",
      "immediately\n",
      "initially\n",
      "implementation\n",
      "ideally\n",
      "instances\n",
      "invocation\n",
      "ineffective\n",
      "infrastructure\n",
      "implement\n",
      "investigation\n",
      "isothermal\n",
      "innovation\n"
     ]
    }
   ],
   "source": [
    "# find top words starting with \"i\".The ten top words include in, is, important, if, it, including, investigational, information, its, include\n",
    "for w in NEJM_fdist:\n",
    "    if w.startswith('i'):\n",
    "        print(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n",
      "on\n",
      "or\n",
      "other\n",
      "outbreak\n",
      "only\n",
      "obtain\n",
      "our\n",
      "ongoing\n",
      "own\n",
      "others\n",
      "one\n",
      "organizations\n",
      "oversight\n",
      "opportunity\n",
      "observational\n",
      "often\n",
      "ones\n",
      "overstate\n",
      "outcome\n",
      "objective\n",
      "outbreaks\n",
      "optimal\n",
      "opportunities\n",
      "optimization\n",
      "obligated\n",
      "obtained\n",
      "occur\n",
      "opposed\n",
      "option\n",
      "outcomes\n",
      "offer\n",
      "opened\n",
      "otherwise-unfettered\n",
      "outset\n",
      "overcame\n",
      "outside\n",
      "operates\n"
     ]
    }
   ],
   "source": [
    "# find top words starting with \"o\".The top ten words include of, on, or, other, outbreak, only, obtain, our, ongoing, own\n",
    "for w in NEJM_fdist:\n",
    "    if w.startswith('o'):\n",
    "        print(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use\n",
      "under\n",
      "used\n",
      "using\n",
      "until\n",
      "up\n",
      "understanding\n",
      "us\n",
      "usually\n",
      "unprecedented\n",
      "users\n",
      "unknown\n",
      "unblind\n",
      "understand\n",
      "unreliable\n",
      "unambiguous\n",
      "unvaccinated\n",
      "unrelated\n",
      "unbiased\n",
      "unblinding\n",
      "unexpected\n",
      "unambiguously\n",
      "ultimate\n",
      "uncommon\n",
      "useful\n",
      "updates\n",
      "unmet\n"
     ]
    }
   ],
   "source": [
    "# find top words starting with \"u\". The top ten words include use, under, used, using, until, up, understanding, us, usually, unprecedented\n",
    "for w in NEJM_fdist:\n",
    "    if w.startswith('u'):\n",
    "        print(w) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
